<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cybersecurity ML Pipeline - Implementation Guide</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <style>
        .code-container {
            max-height: 500px;
            overflow-y: auto;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        .tab-button.active {
            background-color: #3b82f6;
            color: white;
        }
    </style>
</head>
<body class="bg-gray-50 min-h-screen">
    <!-- Header -->
    <header class="bg-gradient-to-r from-blue-900 to-purple-900 text-white py-8">
        <div class="container mx-auto px-6">
            <h1 class="text-4xl font-bold mb-2">Cybersecurity ML Pipeline</h1>
            <p class="text-xl opacity-90">Production-Ready Threat Detection System</p>
            <div class="mt-4">
                <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/9b270223-a31c-45d4-8171-5f476eb85434.png" alt="Cybersecurity dashboard showing network traffic analysis, threat detection graphs, and real-time monitoring displays with dark blue and purple gradient background" class="w-full rounded-lg opacity-80">
            </div>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="bg-white shadow-md sticky top-0 z-50">
        <div class="container mx-auto px-6">
            <div class="flex space-x-8 overflow-x-auto py-4">
                <button onclick="showSection('overview')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg bg-blue-100 text-blue-700 font-medium">Overview</button>
                <button onclick="showSection('structure')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">Project Structure</button>
                <button onclick="showSection('preprocessing')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">Data Pipeline</button>
                <button onclick="showSection('models')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">ML Models</button>
                <button onclick="showSection('api')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">API & Serving</button>
                <button onclick="showSection('agents')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">Agentic AI</button>
                <button onclick="showSection('deployment')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">Deployment</button>
                <button onclick="showSection('monitoring')" class="nav-btn whitespace-nowrap px-4 py-2 rounded-lg hover:bg-gray-100">Monitoring</button>
            </div>
        </div>
    </nav>

    <div class="container mx-auto px-6 py-8">
        <!-- Overview Section -->
        <section id="overview" class="section-content">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">System Architecture Overview</h2>
                <div class="grid md:grid-cols-2 gap-8">
                    <div>
                        <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/2ff876d5-c1c0-415c-98b5-c500bd2d7384.png" alt="System architecture diagram showing data flow from ingestion through feature engineering, model training, serving, and monitoring with interconnected components in a modern technical style" class="w-full rounded-lg shadow-md">
                    </div>
                    <div>
                        <h3 class="text-xl font-semibold mb-4">Key Components</h3>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <span class="bg-blue-100 text-blue-700 px-2 py-1 rounded text-sm font-medium mr-3">Data</span>
                                <span>Automated ingestion with validation (S3, Kafka, CloudWatch)</span>
                            </li>
                            <li class="flex items-start">
                                <span class="bg-green-100 text-green-700 px-2 py-1 rounded text-sm font-medium mr-3">ML</span>
                                <span>Ensemble models with continuous retraining</span>
                            </li>
                            <li class="flex items-start">
                                <span class="bg-purple-100 text-purple-700 px-2 py-1 rounded text-sm font-medium mr-3">API</span>
                                <span>FastAPI serving with async streaming alerts</span>
                            </li>
                            <li class="flex items-start">
                                <span class="bg-orange-100 text-orange-700 px-2 py-1 rounded text-sm font-medium mr-3">Agents</span>
                                <span>Autonomous triage and maintenance assistants</span>
                            </li>
                        </ul>
                        
                        <div class="mt-6 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
                            <h4 class="font-semibold text-yellow-800 mb-2">Quick Start Commands</h4>
                            <div class="text-sm text-yellow-700 space-y-1">
                                <code class="block bg-yellow-100 px-2 py-1 rounded">python3 -m venv venv && source venv/bin/activate</code>
                                <code class="block bg-yellow-100 px-2 py-1 rounded">pip install -r requirements.txt</code>
                                <code class="block bg-yellow-100 px-2 py-1 rounded">python src/train.py --data data/cybersecurity_data.csv</code>
                                <code class="block bg-yellow-100 px-2 py-1 rounded">uvicorn src.app:app --reload</code>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Project Structure Section -->
        <section id="structure" class="section-content hidden">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">Project Structure & Setup</h2>
                <div class="grid lg:grid-cols-2 gap-8">
                    <div>
                        <h3 class="text-xl font-semibold mb-4">Directory Structure</h3>
                        <div class="code-container bg-gray-900 rounded-lg p-4">
                            <pre><code class="language-bash">Cybersecurity-Suspicious-Web-Threat-Interactions/
│
├── data/                      # Raw and processed datasets
│   ├── raw/
│   │   └── cybersecurity_data.csv
│   ├── processed/
│   │   └── features.parquet
│   └── validation/
│       └── schema.json
│
├── notebooks/                 # Jupyter notebooks for EDA
│   ├── 01_EDA.ipynb
│   ├── 02_Feature_Engineering.ipynb
│   └── 03_Model_Evaluation.ipynb
│
├── src/                      # Source code
│   ├── __init__.py
│   ├── app.py               # FastAPI application
│   ├── preprocess.py        # Data preprocessing
│   ├── train.py             # Model training
│   ├── agents/              # Agentic AI components
│   │   ├── triage_agent.py
│   │   └── maintenance_agent.py
│   ├── models/              # Model definitions
│   │   ├── ensemble.py
│   │   ├── isolation_forest.py
│   │   └── autoencoder.py
│   └── utils/               # Utility functions
│       ├── monitoring.py
│       └── security.py
│
├── deploy/                   # Deployment configurations
│   ├── Dockerfile
│   ├── docker-compose.yml
│   └── k8s/                 # Kubernetes manifests
│       ├── deployment.yaml
│       ├── service.yaml
│       └── ingress.yaml
│
├── infra/                    # Infrastructure as code
│   ├── airflow/             # Airflow DAGs
│   │   ├── training_dag.py
│   │   └── monitoring_dag.py
│   └── terraform/           # Infrastructure provisioning
│       └── main.tf
│
├── tests/                    # Unit and integration tests
│   ├── test_preprocess.py
│   ├── test_models.py
│   └── test_api.py
│
├── configs/                  # Configuration files
│   ├── model_config.yaml
│   ├── feature_config.yaml
│   └── deployment_config.yaml
│
├── requirements.txt          # Python dependencies
├── requirements-dev.txt      # Development dependencies
├── Makefile                 # Common commands
├── .github/                 # CI/CD workflows
│   └── workflows/
│       └── ci.yml
└── README.md                # Project documentation</code></pre>
                        </div>
                    </div>
                    <div>
                        <h3 class="text-xl font-semibold mb-4">Requirements.txt</h3>
                        <div class="code-container bg-gray-900 rounded-lg p-4">
                            <pre><code class="language-python"># Core ML Libraries
pandas==2.1.0
numpy==1.24.0
scikit-learn==1.3.0
lightgbm==4.0.0
xgboost==1.7.0
tensorflow==2.13.0

# MLOps & Experiment Tracking
mlflow==2.7.0
feast==0.34.0
great-expectations==0.17.0
evidently==0.4.0

# API & Serving
fastapi==0.103.0
uvicorn[standard]==0.23.0
pydantic==2.3.0
redis==4.6.0

# Data Processing
pyarrow==13.0.0
kafka-python==2.0.2
boto3==1.28.0

# Monitoring & Observability
prometheus-client==0.17.0
sentry-sdk==1.32.0

# Explainability
shap==0.42.0
lime==0.2.0.1

# Agentic AI
langchain==0.0.284
openai==0.28.0
chromadb==0.4.0

# Security
cryptography==41.0.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# Development & Testing
pytest==7.4.0
black==23.7.0
flake8==6.0.0
mypy==1.5.0

# Visualization
matplotlib==3.7.0
seaborn==0.12.0
plotly==5.15.0</code></pre>
                        </div>
                        
                        <div class="mt-6">
                            <h3 class="text-lg font-semibold mb-3">Setup Commands</h3>
                            <div class="bg-gray-100 rounded-lg p-4">
                                <div class="space-y-2 text-sm">
                                    <div><strong>1. Clone and Setup:</strong></div>
                                    <code class="block bg-white px-3 py-2 rounded">git clone <repo-url> && cd Cybersecurity-Suspicious-Web-Threat-Interactions</code>
                                    <code class="block bg-white px-3 py-2 rounded">python3 -m venv venv && source venv/bin/activate</code>
                                    <code class="block bg-white px-3 py-2 rounded">pip install -r requirements.txt</code>
                                    
                                    <div class="mt-4"><strong>2. Initialize MLflow:</strong></div>
                                    <code class="block bg-white px-3 py-2 rounded">mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0</code>
                                    
                                    <div class="mt-4"><strong>3. Run Tests:</strong></div>
                                    <code class="block bg-white px-3 py-2 rounded">pytest tests/ -v</code>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Preprocessing Section -->
        <section id="preprocessing" class="section-content hidden">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">Data Pipeline & Preprocessing</h2>
                
                <!-- Tab Navigation -->
                <div class="flex space-x-4 mb-6 border-b">
                    <button onclick="showTab('preprocess', 'ingestion')" class="tab-button px-4 py-2 font-medium text-blue-600 border-b-2 border-blue-600">Data Ingestion</button>
                    <button onclick="showTab('preprocess', 'validation')" class="tab-button px-4 py-2 font-medium text-gray-500 hover:text-gray-700">Validation</button>
                    <button onclick="showTab('preprocess', 'features')" class="tab-button px-4 py-2 font-medium text-gray-500 hover:text-gray-700">Feature Engineering</button>
                </div>

                <!-- Ingestion Tab -->
                <div id="preprocess-ingestion" class="tab-content active">
                    <h3 class="text-xl font-semibold mb-4">Data Ingestion Pipeline</h3>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/preprocess.py
import pandas as pd
import numpy as np
import pyarrow.parquet as pq
from typing import Dict, List, Optional
import logging
from datetime import datetime
import boto3
from kafka import KafkaConsumer
import json

class DataIngestionPipeline:
    """
    Handles batch and streaming data ingestion with validation
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.s3_client = boto3.client('s3') if config.get('use_s3') else None
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def ingest_batch_csv(self, file_path: str) -> pd.DataFrame:
        """
        Ingest CSV data with preprocessing and normalization
        """
        try:
            # Load data
            df = pd.read_csv(file_path)
            self.logger.info(f"Loaded {len(df)} records from {file_path}")
            
            # Normalize data
            df = self._normalize_data(df)
            
            # Save to parquet for faster access
            parquet_path = file_path.replace('.csv', '.parquet')
            df.to_parquet(parquet_path, index=False)
            self.logger.info(f"Saved processed data to {parquet_path}")
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error ingesting batch data: {e}")
            raise
    
    def _normalize_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Normalize timestamps, IPs, ports, and labels
        """
        # Convert timestamp to datetime
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        
        # Normalize IP addresses
        if 'src_ip' in df.columns:
            df['src_ip'] = df['src_ip'].astype(str)
        if 'dst_ip' in df.columns:
            df['dst_ip'] = df['dst_ip'].astype(str)
        
        # Ensure ports are numeric
        port_columns = ['src_port', 'dst_port']
        for col in port_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Normalize categorical labels
        if 'label' in df.columns:
            df['label'] = df['label'].map({
                'malicious': 1, 'suspicious': 1, 'anomaly': 1,
                'normal': 0, 'benign': 0, 'legitimate': 0
            }).fillna(0)
        
        # Handle missing values
        df = df.fillna(0)
        
        return df
    
    def setup_streaming_ingestion(self) -> KafkaConsumer:
        """
        Setup Kafka consumer for real-time data ingestion
        """
        consumer = KafkaConsumer(
            'cybersecurity-events',
            bootstrap_servers=self.config.get('kafka_servers', ['localhost:9092']),
            value_deserializer=lambda x: json.loads(x.decode('utf-8')),
            auto_offset_reset='latest',
            enable_auto_commit=True
        )
        return consumer
    
    def process_streaming_event(self, event: Dict) -> Dict:
        """
        Process individual streaming events
        """
        try:
            # Normalize event data
            normalized_event = {
                'timestamp': datetime.now().isoformat(),
                'src_ip': event.get('src_ip', ''),
                'dst_ip': event.get('dst_ip', ''),
                'src_port': int(event.get('src_port', 0)),
                'dst_port': int(event.get('dst_port', 0)),
                'protocol': event.get('protocol', ''),
                'bytes_sent': int(event.get('bytes_sent', 0)),
                'bytes_received': int(event.get('bytes_received', 0)),
                'packets_sent': int(event.get('packets_sent', 0)),
                'packets_received': int(event.get('packets_received', 0))
            }
            
            return normalized_event
            
        except Exception as e:
            self.logger.error(f"Error processing streaming event: {e}")
            return {}

# Usage example
if __name__ == "__main__":
    config = {
        'use_s3': False,
        'kafka_servers': ['localhost:9092']
    }
    
    pipeline = DataIngestionPipeline(config)
    
    # Batch ingestion
    df = pipeline.ingest_batch_csv('data/raw/cybersecurity_data.csv')
    print(f"Processed {len(df)} records")
    
    # Streaming setup (run in separate process)
    # consumer = pipeline.setup_streaming_ingestion()
    # for message in consumer:
    #     event = pipeline.process_streaming_event(message.value)
    #     # Process event for real-time inference</code></pre>
                    </div>
                </div>

                <!-- Validation Tab -->
                <div id="preprocess-validation" class="tab-content">
                    <h3 class="text-xl font-semibold mb-4">Data Validation with Great Expectations</h3>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/validation.py
import great_expectations as ge
from great_expectations.core import ExpectationSuite
from great_expectations.checkpoint import SimpleCheckpoint
import pandas as pd
from typing import Dict, List
import logging

class DataValidator:
    """
    Data validation pipeline using Great Expectations
    """
    
    def __init__(self, context_root_dir: str = "./gx"):
        self.context = ge.get_context(context_root_dir=context_root_dir)
        self.logger = logging.getLogger(__name__)
    
    def create_cybersecurity_expectations(self) -> ExpectationSuite:
        """
        Create expectation suite for cybersecurity data
        """
        suite = self.context.create_expectation_suite(
            "cybersecurity_data_suite", 
            overwrite_existing=True
        )
        
        # Core column expectations
        expectations = [
            # Timestamp expectations
            {
                "expectation_type": "expect_column_to_exist",
                "kwargs": {"column": "timestamp"}
            },
            {
                "expectation_type": "expect_column_values_to_not_be_null",
                "kwargs": {"column": "timestamp"}
            },
            
            # IP address expectations
            {
                "expectation_type": "expect_column_to_exist",
                "kwargs": {"column": "src_ip"}
            },
            {
                "expectation_type": "expect_column_values_to_match_regex",
                "kwargs": {
                    "column": "src_ip",
                    "regex": r"^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$"
                }
            },
            
            # Port expectations
            {
                "expectation_type": "expect_column_values_to_be_between",
                "kwargs": {
                    "column": "src_port",
                    "min_value": 0,
                    "max_value": 65535
                }
            },
            {
                "expectation_type": "expect_column_values_to_be_between",
                "kwargs": {
                    "column": "dst_port", 
                    "min_value": 0,
                    "max_value": 65535
                }
            },
            
            # Traffic volume expectations
            {
                "expectation_type": "expect_column_values_to_be_between",
                "kwargs": {
                    "column": "bytes_sent",
                    "min_value": 0,
                    "max_value": 1e10  # 10GB max
                }
            },
            
            # Label expectations
            {
                "expectation_type": "expect_column_values_to_be_in_set",
                "kwargs": {
                    "column": "label",
                    "value_set": [0, 1]
                }
            },
            
            # Data completeness
            {
                "expectation_type": "expect_table_row_count_to_be_between",
                "kwargs": {
                    "min_value": 100,  # Minimum viable dataset
                    "max_value": 1e7   # Maximum processing capacity
                }
            }
        ]
        
        # Add expectations to suite
        for exp in expectations:
            suite.add_expectation(**exp)
        
        self.context.save_expectation_suite(suite)
        return suite
    
    def validate_batch(self, df: pd.DataFrame, suite_name: str = "cybersecurity_data_suite") -> Dict:
        """
        Validate a batch of data against expectations
        """
        try:
            # Create validator
            validator = self.context.get_validator(
                batch_request={
                    "datasource_name": "pandas_datasource",
                    "data_connector_name": "default_inferred_data_connector",
                    "data_asset_name": "cybersecurity_data",
                    "batch_data": df
                },
                expectation_suite_name=suite_name
            )
            
            # Run validation
            validation_result = validator.validate()
            
            # Log results
            if validation_result.success:
                self.logger.info("Data validation passed!")
            else:
                self.logger.warning(f"Data validation failed with {len(validation_result.unsuccessful_expectations)} issues")
                for result in validation_result.unsuccessful_expectations:
                    self.logger.warning(f"Failed: {result.expectation_config.expectation_type}")
            
            return {
                "success": validation_result.success,
                "statistics": validation_result.statistics,
                "results": validation_result.results
            }
            
        except Exception as e:
            self.logger.error(f"Validation error: {e}")
            return {"success": False, "error": str(e)}
    
    def create_checkpoint(self, suite_name: str) -> SimpleCheckpoint:
        """
        Create checkpoint for automated validation
        """
        checkpoint_config = {
            "name": "cybersecurity_checkpoint",
            "config_version": 1.0,
            "template_name": None,
            "module_name": "great_expectations.checkpoint",
            "class_name": "SimpleCheckpoint",
            "run_name_template": "%Y%m%d-%H%M%S-cybersecurity-validation",
            "expectation_suite_name": suite_name,
            "batch_request": {},
            "action_list": [
                {
                    "name": "store_validation_result",
                    "action": {
                        "class_name": "StoreValidationResultAction"
                    }
                },
                {
                    "name": "update_data_docs",
                    "action": {
                        "class_name": "UpdateDataDocsAction"
                    }
                }
            ]
        }
        
        checkpoint = SimpleCheckpoint(**checkpoint_config)
        self.context.add_checkpoint(**checkpoint_config)
        return checkpoint

# Usage
if __name__ == "__main__":
    # Initialize validator
    validator = DataValidator()
    
    # Create expectations
    suite = validator.create_cybersecurity_expectations()
    
    # Load and validate data
    df = pd.read_csv("data/cybersecurity_data.csv")
    results = validator.validate_batch(df)
    
    if not results["success"]:
        print("Validation failed! Check logs for details.")
        exit(1)
    else:
        print("Data validation passed!")</code></pre>
                    </div>
                </div>

                <!-- Features Tab -->
                <div id="preprocess-features" class="tab-content">
                    <h3 class="text-xl font-semibold mb-4">Feature Engineering Pipeline</h3>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/feature_engineering.py
import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, LabelEncoder
import geoip2.database
from typing import Dict, List, Optional
import joblib

class CyberSecurityFeatureEngineer(BaseEstimator, TransformerMixin):
    """
    Custom feature engineering for cybersecurity data
    """
    
    def __init__(self, geoip_db_path: Optional[str] = None):
        self.geoip_db_path = geoip_db_path
        self.geoip_reader = None
        self.ip_encoders = {}
        self.feature_names = []
    
    def fit(self, X: pd.DataFrame, y=None):
        """
        Fit the feature engineer on training data
        """
        if self.geoip_db_path:
            self.geoip_reader = geoip2.database.Reader(self.geoip_db_path)
        
        # Fit label encoders for categorical features
        categorical_cols = ['protocol', 'src_ip_country', 'dst_ip_country']
        for col in categorical_cols:
            if col in X.columns:
                encoder = LabelEncoder()
                encoder.fit(X[col].fillna('unknown'))
                self.ip_encoders[col] = encoder
        
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        Transform data with engineered features
        """
        X_transformed = X.copy()
        
        # Time-based features
        X_transformed = self._add_time_features(X_transformed)
        
        # Traffic analysis features
        X_transformed = self._add_traffic_features(X_transformed)
        
        # Geolocation features
        if self.geoip_reader:
            X_transformed = self._add_geo_features(X_transformed)
        
        # Statistical features
        X_transformed = self._add_statistical_features(X_transformed)
        
        # Network behavior features
        X_transformed = self._add_network_features(X_transformed)
        
        # Encode categorical features
        X_transformed = self._encode_categorical(X_transformed)
        
        # Store feature names
        self.feature_names = list(X_transformed.columns)
        
        return X_transformed
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Extract time-based features
        """
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df['hour'] = df['timestamp'].dt.hour
            df['day_of_week'] = df['timestamp'].dt.dayofweek
            df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
            df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)
        
        return df
    
    def _add_traffic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Compute traffic analysis features
        """
        # Bytes ratio
        df['bytes_ratio'] = (
            df['bytes_sent'] / (df['bytes_sent'] + df['bytes_received'] + 1e-6)
        )
        
        # Packets ratio
        df['packets_ratio'] = (
            df['packets_sent'] / (df['packets_sent'] + df['packets_received'] + 1e-6)
        )
        
        # Average packet size
        df['avg_packet_size_sent'] = (
            df['bytes_sent'] / (df['packets_sent'] + 1e-6)
        )
        df['avg_packet_size_received'] = (
            df['bytes_received'] / (df['packets_received'] + 1e-6)
        )
        
        # Total traffic volume
        df['total_bytes'] = df['bytes_sent'] + df['bytes_received']
        df['total_packets'] = df['packets_sent'] + df['packets_received']
        
        # Traffic rate (if duration available)
        if 'duration' in df.columns:
            df['bytes_per_second'] = df['total_bytes'] / (df['duration'] + 1e-6)
            df['packets_per_second'] = df['total_packets'] / (df['duration'] + 1e-6)
        
        return df
    
    def _add_geo_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Add geolocation features using IP addresses
        """
        for ip_col in ['src_ip', 'dst_ip']:
            if ip_col in df.columns:
                country_col = f"{ip_col}_country"
                df[country_col] = df[ip_col].apply(self._get_country)
        
        # Cross-border communication flag
        if 'src_ip_country' in df.columns and 'dst_ip_country' in df.columns:
            df['is_cross_border'] = (
                df['src_ip_country'] != df['dst_ip_country']
            ).astype(int)
        
        return df
    
    def _get_country(self, ip: str) -> str:
        """
        Get country from IP address
        """
        try:
            if self.geoip_reader:
                response = self.geoip_reader.country(ip)
                return response.country.iso_code or 'unknown'
        except:
            pass
        return 'unknown'
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Add statistical aggregations by IP and port
        """
        # Group by source IP and compute statistics
        src_ip_stats = df.groupby('src_ip').agg({
            'total_bytes': ['count', 'mean', 'std'],
            'dst_port': 'nunique'
        }).round(3)
        
        src_ip_stats.columns = [
            'src_ip_session_count', 'src_ip_avg_bytes', 'src_ip_std_bytes',
            'src_ip_unique_ports'
        ]
        
        df = df.merge(src_ip_stats, on='src_ip', how='left')
        
        # Similar for destination ports
        dst_port_stats = df.groupby('dst_port').agg({
            'total_bytes': ['count', 'mean'],
            'src_ip': 'nunique'
        }).round(3)
        
        dst_port_stats.columns = [
            'dst_port_session_count', 'dst_port_avg_bytes', 'dst_port_unique_ips'
        ]
        
        df = df.merge(dst_port_stats, on='dst_port', how='left')
        
        return df
    
    def _add_network_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Add network behavior features
        """
        # Port classification
        df['is_well_known_port'] = (df['dst_port'] <= 1023).astype(int)
        df['is_ephemeral_port'] = (df['dst_port'] >= 49152).astype(int)
        
        # Protocol analysis
        if 'protocol' in df.columns:
            df['is_tcp'] = (df['protocol'].str.upper() == 'TCP').astype(int)
            df['is_udp'] = (df['protocol'].str.upper() == 'UDP').astype(int)
        
        # Suspicious patterns
        df['high_bytes_low_packets'] = (
            (df['total_bytes'] > df['total_bytes'].quantile(0.9)) &
            (df['total_packets'] < df['total_packets'].quantile(0.1))
        ).astype(int)
        
        return df
    
    def _encode_categorical(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Encode categorical variables
        """
        for col, encoder in self.ip_encoders.items():
            if col in df.columns:
                df[col] = encoder.transform(df[col].fillna('unknown'))
        
        return df

def create_feature_pipeline() -> Pipeline:
    """
    Create complete feature engineering pipeline
    """
    pipeline = Pipeline([
        ('feature_engineer', CyberSecurityFeatureEngineer()),
        ('scaler', StandardScaler())
    ])
    
    return pipeline

# Usage example
if __name__ == "__main__":
    # Load data
    df = pd.read_csv("data/cybersecurity_data.csv")
    
    # Create and fit pipeline
    pipeline = create_feature_pipeline()
    X_processed = pipeline.fit_transform(df.drop('label', axis=1))
    
    # Save pipeline
    joblib.dump(pipeline, "models/feature_pipeline.joblib")
    
    print(f"Processed features shape: {X_processed.shape}")
    print(f"Feature names: {pipeline.named_steps['feature_engineer'].feature_names[:10]}...")</code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- Models Section -->
        <section id="models" class="section-content hidden">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">ML Models & Training</h2>
                
                <!-- Tab Navigation -->
                <div class="flex space-x-4 mb-6 border-b">
                    <button onclick="showTab('models', 'ensemble')" class="tab-button px-4 py-2 font-medium text-blue-600 border-b-2 border-blue-600">Ensemble Models</button>
                    <button onclick="showTab('models', 'unsupervised')" class="tab-button px-4 py-2 font-medium text-gray-500 hover:text-gray-700">Unsupervised</button>
                    <button onclick="showTab('models', 'training')" class="tab-button px-4 py-2 font-medium text-gray-500 hover:text-gray-700">Training Pipeline</button>
                </div>

                <!-- Ensemble Tab -->
                <div id="models-ensemble" class="tab-content active">
                    <h3 class="text-xl font-semibold mb-4">Ensemble Model Architecture</h3>
                    <div class="mb-4">
                        <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/66837ce9-cae2-410e-b14c-763246f5b9b2.png" alt="Ensemble model architecture diagram showing multiple model types including isolation forest, autoencoder, and gradient boosting models feeding into a meta-learner with stacking approach" class="w-full rounded-lg shadow-md">
                    </div>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/models/ensemble.py
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import roc_auc_score, precision_recall_curve
import lightgbm as lgb
import xgboost as xgb
from tensorflow import keras
import mlflow
import mlflow.sklearn
import mlflow.tensorflow
from typing import Dict, List, Tuple, Any
import joblib

class CyberSecurityEnsemble:
    """
    Advanced ensemble model for cybersecurity threat detection
    """
    
    def __init__(self, config: Dict = None):
        self.config = config or self._default_config()
        self.models = {}
        self.meta_model = None
        self.feature_importance = {}
        
    def _default_config(self) -> Dict:
        return {
            'isolation_forest': {
                'contamination': 0.1,
                'n_estimators': 100,
                'random_state': 42
            },
            'lightgbm': {
                'objective': 'binary',
                'metric': 'auc',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': 42
            },
            'xgboost': {
                'objective': 'binary:logistic',
                'eval_metric': 'auc',
                'max_depth': 6,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42
            },
            'autoencoder': {
                'encoding_dim': 32,
                'epochs': 50,
                'batch_size': 256,
                'validation_split': 0.2
            }
        }
    
    def build_autoencoder(self, input_dim: int) -> keras.Model:
        """
        Build autoencoder for anomaly detection
        """
        # Encoder
        input_layer = keras.layers.Input(shape=(input_dim,))
        encoder = keras.layers.Dense(64, activation='relu')(input_layer)
        encoder = keras.layers.Dropout(0.2)(encoder)
        encoder = keras.layers.Dense(self.config['autoencoder']['encoding_dim'], 
                                   activation='relu')(encoder)
        
        # Decoder
        decoder = keras.layers.Dense(64, activation='relu')(encoder)
        decoder = keras.layers.Dropout(0.2)(decoder)
        decoder = keras.layers.Dense(input_dim, activation='linear')(decoder)
        
        # Autoencoder model
        autoencoder = keras.Model(input_layer, decoder)
        autoencoder.compile(optimizer='adam', loss='mse')
        
        return autoencoder
    
    def fit(self, X_train: np.ndarray, y_train: np.ndarray, 
            X_val: np.ndarray = None, y_val: np.ndarray = None) -> Dict:
        """
        Train ensemble of models
        """
        results = {}
        
        with mlflow.start_run(run_name="cybersecurity_ensemble"):
            # 1. Isolation Forest (Unsupervised)
            print("Training Isolation Forest...")
            iso_forest = IsolationForest(**self.config['isolation_forest'])
            iso_forest.fit(X_train)
            self.models['isolation_forest'] = iso_forest
            
            # Log isolation forest
            mlflow.sklearn.log_model(iso_forest, "isolation_forest")
            
            # 2. LightGBM (Supervised)
            print("Training LightGBM...")
            lgb_train = lgb.Dataset(X_train, label=y_train)
            lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train) if X_val is not None else None
            
            lgb_model = lgb.train(
                self.config['lightgbm'],
                lgb_train,
                valid_sets=[lgb_val] if lgb_val else None,
                num_boost_round=1000,
                callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]
            )
            self.models['lightgbm'] = lgb_model
            
            # 3. XGBoost (Supervised)
            print("Training XGBoost...")
            xgb_model = xgb.XGBClassifier(**self.config['xgboost'])
            xgb_model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)] if X_val is not None else None,
                early_stopping_rounds=100,
                verbose=False
            )
            self.models['xgboost'] = xgb_model
            
            # 4. Autoencoder (Unsupervised)
            print("Training Autoencoder...")
            autoencoder = self.build_autoencoder(X_train.shape[1])
            
            # Train on normal data only for better anomaly detection
            normal_data = X_train[y_train == 0]
            history = autoencoder.fit(
                normal_data, normal_data,
                epochs=self.config['autoencoder']['epochs'],
                batch_size=self.config['autoencoder']['batch_size'],
                validation_split=self.config['autoencoder']['validation_split'],
                verbose=0
            )
            self.models['autoencoder'] = autoencoder
            
            # 5. Create meta-features for stacking
            print("Creating meta-features...")
            meta_features_train = self._create_meta_features(X_train)
            
            # 6. Train meta-model (LightGBM)
            print("Training meta-model...")
            meta_lgb_train = lgb.Dataset(meta_features_train, label=y_train)
            meta_model = lgb.train(
                {**self.config['lightgbm'], 'learning_rate': 0.02},
                meta_lgb_train,
                num_boost_round=500,
                callbacks=[lgb.log_evaluation(0)]
            )
            self.meta_model = meta_model
            
            # Validation if provided
            if X_val is not None:
                val_predictions = self.predict_proba(X_val)
                val_auc = roc_auc_score(y_val, val_predictions)
                results['validation_auc'] = val_auc
                mlflow.log_metric("validation_auc", val_auc)
                
                # Precision at different thresholds
                precision, recall, thresholds = precision_recall_curve(y_val, val_predictions)
                results['validation_pr_auc'] = np.trapz(precision, recall)
                mlflow.log_metric("validation_pr_auc", results['validation_pr_auc'])
            
            # Feature importance
            self.feature_importance = {
                'lightgbm': dict(zip(range(len(lgb_model.feature_importance())), 
                                   lgb_model.feature_importance())),
                'xgboost': dict(zip(range(len(xgb_model.feature_importances_)), 
                                  xgb_model.feature_importances_))
            }
            
            # Log models
            mlflow.lightgbm.log_model(lgb_model, "lightgbm")
            mlflow.sklearn.log_model(xgb_model, "xgboost")
            mlflow.tensorflow.log_model(autoencoder, "autoencoder")
            mlflow.lightgbm.log_model(meta_model, "meta_model")
            
        return results
    
    def _create_meta_features(self, X: np.ndarray) -> np.ndarray:
        """
        Create meta-features from base models
        """
        meta_features = []
        
        # Isolation Forest anomaly scores
        iso_scores = self.models['isolation_forest'].decision_function(X)
        meta_features.append(iso_scores.reshape(-1, 1))
        
        # LightGBM predictions
        lgb_preds = self.models['lightgbm'].predict(X)
        meta_features.append(lgb_preds.reshape(-1, 1))
        
        # XGBoost predictions
        xgb_preds = self.models['xgboost'].predict_proba(X)[:, 1]
        meta_features.append(xgb_preds.reshape(-1, 1))
        
        # Autoencoder reconstruction error
        ae_preds = self.models['autoencoder'].predict(X)
        reconstruction_error = np.mean(np.square(X - ae_preds), axis=1)
        meta_features.append(reconstruction_error.reshape(-1, 1))
        
        return np.hstack(meta_features)
    
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """
        Predict probabilities using ensemble
        """
        meta_features = self._create_meta_features(X)
        meta_predictions = self.meta_model.predict(meta_features)
        return meta_predictions
    
    def predict(self, X: np.ndarray, threshold: float = 0.5) -> np.ndarray:
        """
        Binary predictions
        """
        probabilities = self.predict_proba(X)
        return (probabilities >= threshold).astype(int)
    
    def get_feature_importance(self) -> Dict:
        """
        Get aggregated feature importance
        """
        return self.feature_importance
    
    def save_models(self, path: str):
        """
        Save all models to disk
        """
        models_to_save = {
            'config': self.config,
            'feature_importance': self.feature_importance
        }
        
        # Save sklearn-compatible models
        for name, model in self.models.items():
            if name != 'autoencoder':
                models_to_save[name] = model
        
        models_to_save['meta_model'] = self.meta_model
        
        # Save autoencoder separately
        if 'autoencoder' in self.models:
            self.models['autoencoder'].save(f"{path}/autoencoder.h5")
        
        joblib.dump(models_to_save, f"{path}/ensemble_models.joblib")
    
    def load_models(self, path: str):
        """
        Load models from disk
        """
        models_data = joblib.load(f"{path}/ensemble_models.joblib")
        
        self.config = models_data['config']
        self.feature_importance = models_data['feature_importance']
        self.meta_model = models_data['meta_model']
        
        # Load individual models
        for name in ['isolation_forest', 'lightgbm', 'xgboost']:
            if name in models_data:
                self.models[name] = models_data[name]
        
        # Load autoencoder
        try:
            self.models['autoencoder'] = keras.models.load_model(f"{path}/autoencoder.h5")
        except:
            print("Warning: Could not load autoencoder model")

# Usage example
if __name__ == "__main__":
    # Example usage
    from sklearn.model_selection import train_test_split
    from sklearn.datasets import make_classification
    
    # Generate sample data (replace with your actual data loading)
    X, y = make_classification(n_samples=10000, n_features=20, n_classes=2, 
                             n_informative=15, random_state=42)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Train ensemble
    ensemble = CyberSecurityEnsemble()
    results = ensemble.fit(X_train, y_train, X_test, y_test)
    
    # Make predictions
    predictions = ensemble.predict_proba(X_test)
    test_auc = roc_auc_score(y_test, predictions)
    
    print(f"Test AUC: {test_auc:.4f}")
    
    # Save models
    ensemble.save_models("models")</code></pre>
                    </div>
                </div>

                <!-- Unsupervised Tab -->
                <div id="models-unsupervised" class="tab-content">
                    <h3 class="text-xl font-semibold mb-4">Unsupervised Anomaly Detection</h3>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/models/unsupervised.py
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Tuple, List
import joblib

class UnsupervisedAnomalyDetector:
    """
    Collection of unsupervised models for anomaly detection
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.thresholds = {}
        
    def fit_isolation_forest(self, X: np.ndarray, contamination: float = 0.1) -> Dict:
        """
        Fit Isolation Forest model
        """
        # Scale features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Fit Isolation Forest
        iso_forest = IsolationForest(
            contamination=contamination,
            n_estimators=200,
            max_samples='auto',
            random_state=42,
            n_jobs=-1
        )
        iso_forest.fit(X_scaled)
        
        # Store models
        self.models['isolation_forest'] = iso_forest
        self.scalers['isolation_forest'] = scaler
        
        # Get anomaly scores
        scores = iso_forest.decision_function(X_scaled)
        threshold = np.percentile(scores, contamination * 100)
        self.thresholds['isolation_forest'] = threshold
        
        return {
            'model': iso_forest,
            'scaler': scaler,
            'threshold': threshold,
            'scores': scores
        }
    
    def fit_autoencoder(self, X: np.ndarray, encoding_dim: int = 32, 
                       epochs: int = 100) -> Dict:
        """
        Fit Autoencoder model
        """
        # Scale features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        input_dim = X_scaled.shape[1]
        
        # Build autoencoder architecture
        input_layer = keras.Input(shape=(input_dim,))
        
        # Encoder
        encoded = layers.Dense(128, activation='relu')(input_layer)
        encoded = layers.Dropout(0.2)(encoded)
        encoded = layers.Dense(64, activation='relu')(encoded)
        encoded = layers.Dropout(0.2)(encoded)
        encoded = layers.Dense(encoding_dim, activation='relu')(encoded)
        
        # Decoder
        decoded = layers.Dense(64, activation='relu')(encoded)
        decoded = layers.Dropout(0.2)(decoded)
        decoded = layers.Dense(128, activation='relu')(decoded)
        decoded = layers.Dropout(0.2)(decoded)
        decoded = layers.Dense(input_dim, activation='linear')(decoded)
        
        # Create and compile model
        autoencoder = keras.Model(input_layer, decoded)
        autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])
        
        # Train model
        history = autoencoder.fit(
            X_scaled, X_scaled,
            epochs=epochs,
            batch_size=256,
            validation_split=0.2,
            verbose=1,
            callbacks=[
                keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
                keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)
            ]
        )
        
        # Calculate reconstruction errors
        reconstructed = autoencoder.predict(X_scaled)
        reconstruction_errors = np.mean(np.square(X_scaled - reconstructed), axis=1)
        
        # Set threshold at 95th percentile
        threshold = np.percentile(reconstruction_errors, 95)
        
        # Store models
        self.models['autoencoder'] = autoencoder
        self.scalers['autoencoder'] = scaler
        self.thresholds['autoencoder'] = threshold
        
        return {
            'model': autoencoder,
            'scaler': scaler,
            'threshold': threshold,
            'reconstruction_errors': reconstruction_errors,
            'history': history
        }
    
    def fit_clustering_outliers(self, X: np.ndarray, eps: float = 0.5, 
                               min_samples: int = 5) -> Dict:
        """
        Use DBSCAN clustering to identify outliers
        """
        # Scale features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Apply PCA for dimensionality reduction
        pca = PCA(n_components=0.95)  # Keep 95% of variance
        X_pca = pca.fit_transform(X_scaled)
        
        # Fit DBSCAN
        dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)
        cluster_labels = dbscan.fit_predict(X_pca)
        
        # Points labeled as -1 are outliers
        outlier_mask = cluster_labels == -1
        
        # Store models
        self.models['dbscan'] = dbscan
        self.scalers['dbscan'] = scaler
        self.models['pca'] = pca
        
        return {
            'model': dbscan,
            'pca': pca,
            'scaler': scaler,
            'cluster_labels': cluster_labels,
            'outlier_mask': outlier_mask,
            'n_clusters': len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
        }
    
    def predict_anomalies(self, X: np.ndarray, method: str = 'ensemble') -> Dict:
        """
        Predict anomalies using specified method or ensemble
        """
        results = {}
        
        if method == 'isolation_forest' or method == 'ensemble':
            if 'isolation_forest' in self.models:
                X_scaled = self.scalers['isolation_forest'].transform(X)
                iso_scores = self.models['isolation_forest'].decision_function(X_scaled)
                iso_anomalies = iso_scores < self.thresholds['isolation_forest']
                results['isolation_forest'] = {
                    'scores': iso_scores,
                    'anomalies': iso_anomalies,
                    'anomaly_ratio': np.mean(iso_anomalies)
                }
        
        if method == 'autoencoder' or method == 'ensemble':
            if 'autoencoder' in self.models:
                X_scaled = self.scalers['autoencoder'].transform(X)
                reconstructed = self.models['autoencoder'].predict(X_scaled)
                reconstruction_errors = np.mean(np.square(X_scaled - reconstructed), axis=1)
                ae_anomalies = reconstruction_errors > self.thresholds['autoencoder']
                results['autoencoder'] = {
                    'reconstruction_errors': reconstruction_errors,
                    'anomalies': ae_anomalies,
                    'anomaly_ratio': np.mean(ae_anomalies)
                }
        
        if method == 'dbscan' or method == 'ensemble':
            if 'dbscan' in self.models:
                X_scaled = self.scalers['dbscan'].transform(X)
                X_pca = self.models['pca'].transform(X_scaled)
                cluster_labels = self.models['dbscan'].fit_predict(X_pca)
                dbscan_anomalies = cluster_labels == -1
                results['dbscan'] = {
                    'cluster_labels': cluster_labels,
                    'anomalies': dbscan_anomalies,
                    'anomaly_ratio': np.mean(dbscan_anomalies)
                }
        
        # Ensemble prediction (majority vote)
        if method == 'ensemble' and len(results) > 1:
            anomaly_votes = np.zeros(len(X))
            for model_results in results.values():
                anomaly_votes += model_results['anomalies'].astype(int)
            
            ensemble_anomalies = anomaly_votes >= (len(results) / 2)
            results['ensemble'] = {
                'votes': anomaly_votes,
                'anomalies': ensemble_anomalies,
                'anomaly_ratio': np.mean(ensemble_anomalies)
            }
        
        return results
    
    def visualize_anomalies(self, X: np.ndarray, anomalies: np.ndarray, 
                           method: str = 'PCA', figsize: Tuple[int, int] = (12, 8)):
        """
        Visualize anomalies in 2D space
        """
        if method == 'PCA':
            # Use PCA for dimensionality reduction
            pca = PCA(n_components=2)
            X_pca = pca.fit_transform(StandardScaler().fit_transform(X))
            
            plt.figure(figsize=figsize)
            plt.scatter(X_pca[~anomalies, 0], X_pca[~anomalies, 1], 
                       c='blue', alpha=0.6, label='Normal', s=50)
            plt.scatter(X_pca[anomalies, 0], X_pca[anomalies, 1], 
                       c='red', alpha=0.8, label='Anomaly', s=100, marker='^')
            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
            plt.title('Anomaly Detection Results (PCA Projection)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.show()
    
    def get_anomaly_statistics(self, results: Dict) -> pd.DataFrame:
        """
        Get statistics about detected anomalies
        """
        stats = []
        for method, result in results.items():
            if 'anomalies' in result:
                stats.append({
                    'Method': method,
                    'Total Anomalies': np.sum(result['anomalies']),
                    'Anomaly Ratio': result['anomaly_ratio'],
                    'Normal Samples': np.sum(~result['anomalies'])
                })
        
        return pd.DataFrame(stats)
    
    def save_models(self, path: str):
        """
        Save all models and scalers
        """
        models_to_save = {
            'scalers': self.scalers,
            'thresholds': self.thresholds
        }
        
        # Save non-Keras models
        for name, model in self.models.items():
            if name != 'autoencoder':
                models_to_save[name] = model
        
        joblib.dump(models_to_save, f"{path}/unsupervised_models.joblib")
        
        # Save autoencoder separately if it exists
        if 'autoencoder' in self.models:
            self.models['autoencoder'].save(f"{path}/autoencoder_unsupervised.h5")
    
    def load_models(self, path: str):
        """
        Load models and scalers
        """
        models_data = joblib.load(f"{path}/unsupervised_models.joblib")
        
        self.scalers = models_data['scalers']
        self.thresholds = models_data['thresholds']
        
        # Load individual models
        for name in ['isolation_forest', 'dbscan', 'pca']:
            if name in models_data:
                self.models[name] = models_data[name]
        
        # Load autoencoder if it exists
        try:
            self.models['autoencoder'] = keras.models.load_model(f"{path}/autoencoder_unsupervised.h5")
        except:
            print("Warning: Could not load autoencoder model")

# Usage example
if __name__ == "__main__":
    # Generate sample data
    from sklearn.datasets import make_blobs
    
    # Create normal data
    X_normal, _ = make_blobs(n_samples=1000, centers=3, n_features=10, 
                            cluster_std=1.0, random_state=42)
    
    # Add some anomalies
    X_anomalies = np.random.uniform(low=-6, high=6, size=(50, 10))
    X = np.vstack([X_normal, X_anomalies])
    
    # True labels (for evaluation)
    y_true = np.hstack([np.zeros(1000), np.ones(50)])
    
    # Fit models
    detector = UnsupervisedAnomalyDetector()
    
    # Fit different models
    iso_results = detector.fit_isolation_forest(X, contamination=0.05)
    ae_results = detector.fit_autoencoder(X, encoding_dim=5, epochs=50)
    cluster_results = detector.fit_clustering_outliers(X)
    
    # Predict anomalies
    predictions = detector.predict_anomalies(X, method='ensemble')
    
    # Get statistics
    stats = detector.get_anomaly_statistics(predictions)
    print("Anomaly Detection Statistics:")
    print(stats)
    
    # Visualize results
    if 'ensemble' in predictions:
        detector.visualize_anomalies(X, predictions['ensemble']['anomalies'])
    
    # Save models
    detector.save_models("models/unsupervised")</code></pre>
                    </div>
                </div>

                <!-- Training Tab -->
                <div id="models-training" class="tab-content">
                    <h3 class="text-xl font-semibold mb-4">Training Pipeline with MLflow</h3>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/train.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, precision_recall_curve, classification_report
import mlflow
import mlflow.sklearn
import mlflow.lightgbm
import argparse
import yaml
import joblib
from pathlib import Path
import logging
from typing import Dict, Tuple

from feature_engineering import create_feature_pipeline
from models.ensemble import CyberSecurityEnsemble
from validation import DataValidator

class ModelTrainingPipeline:
    """
    Complete training pipeline with MLflow tracking
    """
    
    def __init__(self, config_path: str = "configs/model_config.yaml"):
        self.config = self._load_config(config_path)
        self.setup_logging()
        self.setup_mlflow()
        
    def _load_config(self, config_path: str) -> Dict:
        """Load configuration from YAML file"""
        try:
            with open(config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            return self._default_config()
    
    def _default_config(self) -> Dict:
        """Default configuration"""
        return {
            'data': {
                'test_size': 0.2,
                'validation_size': 0.2,
                'random_state': 42
            },
            'training': {
                'cv_folds': 5,
                'scoring': 'roc_auc',
                'n_trials': 50  # for hyperparameter optimization
            },
            'mlflow': {
                'experiment_name': 'cybersecurity_threat_detection',
                'tracking_uri': 'sqlite:///mlflow.db'
            },
            'model_registry': {
                'model_name': 'cybersecurity_ensemble',
                'stage': 'Staging'
            }
        }
    
    def setup_logging(self):
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def setup_mlflow(self):
        """Setup MLflow tracking"""
        mlflow.set_tracking_uri(self.config['mlflow']['tracking_uri'])
        
        try:
            experiment = mlflow.get_experiment_by_name(
                self.config['mlflow']['experiment_name']
            )
            if experiment is None:
                experiment_id = mlflow.create_experiment(
                    self.config['mlflow']['experiment_name']
                )
            else:
                experiment_id = experiment.experiment_id
                
            mlflow.set_experiment(experiment_id=experiment_id)
            
        except Exception as e:
            self.logger.error(f"MLflow setup error: {e}")
    
    def load_and_validate_data(self, data_path: str) -> Tuple[pd.DataFrame, bool]:
        """
        Load and validate data using Great Expectations
        """
        self.logger.info(f"Loading data from {data_path}")
        
        # Load data
        if data_path.endswith('.csv'):
            df = pd.read_csv(data_path)
        elif data_path.endswith('.parquet'):
            df = pd.read_parquet(data_path)
        else:
            raise ValueError("Unsupported file format. Use CSV or Parquet.")
        
        # Validate data
        validator = DataValidator()
        suite = validator.create_cybersecurity_expectations()
        validation_results = validator.validate_batch(df)
        
        if not validation_results['success']:
            self.logger.warning("Data validation failed!")
            return df, False
        
        self.logger.info("Data validation passed!")
        return df, True
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        Prepare features using feature engineering pipeline
        """
        self.logger.info("Starting feature engineering...")
        
        # Separate features and target
        if 'label' not in df.columns:
            raise ValueError("Target column 'label' not found in data")
        
        X = df.drop('label', axis=1)
        y = df['label'].values
        
        # Create and fit feature pipeline
        self.feature_pipeline = create_feature_pipeline()
        X_processed = self.feature_pipeline.fit_transform(X)
        
        # Save feature pipeline
        Path("models").mkdir(exist_ok=True)
        joblib.dump(self.feature_pipeline, "models/feature_pipeline.joblib")
        
        self.logger.info(f"Feature engineering complete. Shape: {X_processed.shape}")
        return X_processed, y
    
    def split_data(self, X: np.ndarray, y: np.ndarray) -> Tuple:
        """
        Split data into train/validation/test sets
        """
        # First split: train + val / test
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y,
            test_size=self.config['data']['test_size'],
            random_state=self.config['data']['random_state'],
            stratify=y
        )
        
        # Second split: train / val
        val_size = self.config['data']['validation_size'] / (1 - self.config['data']['test_size'])
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=val_size,
            random_state=self.config['data']['random_state'],
            stratify=y_temp
        )
        
        self.logger.info(f"Data split - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def train_model(self, X_train: np.ndarray, y_train: np.ndarray,
                   X_val: np.ndarray, y_val: np.ndarray) -> CyberSecurityEnsemble:
        """
        Train ensemble model with cross-validation
        """
        self.logger.info("Training ensemble model...")
        
        with mlflow.start_run(run_name="ensemble_training"):
            # Log parameters
            mlflow.log_params({
                'train_size': len(X_train),
                'val_size': len(X_val),
                'n_features': X_train.shape[1],
                'positive_ratio': np.mean(y_train)
            })
            
            # Initialize and train ensemble
            ensemble = CyberSecurityEnsemble()
            training_results = ensemble.fit(X_train, y_train, X_val, y_val)
            
            # Log training metrics
            if 'validation_auc' in training_results:
                mlflow.log_metric("validation_auc", training_results['validation_auc'])
            if 'validation_pr_auc' in training_results:
                mlflow.log_metric("validation_pr_auc", training_results['validation_pr_auc'])
            
            # Cross-validation
            self.logger.info("Performing cross-validation...")
            cv_scores = self._cross_validate(ensemble, X_train, y_train)
            
            # Log CV metrics
            mlflow.log_metrics({
                'cv_auc_mean': np.mean(cv_scores),
                'cv_auc_std': np.std(cv_scores),
                'cv_auc_min': np.min(cv_scores),
                'cv_auc_max': np.max(cv_scores)
            })
            
            # Save model artifacts
            Path("models/ensemble").mkdir(parents=True, exist_ok=True)
            ensemble.save_models("models/ensemble")
            
            # Log model
            mlflow.log_artifacts("models/ensemble", "ensemble_models")
            
            return ensemble
    
    def _cross_validate(self, ensemble: CyberSecurityEnsemble, 
                       X: np.ndarray, y: np.ndarray) -> np.ndarray:
        """
        Perform stratified cross-validation
        """
        cv = StratifiedKFold(
            n_splits=self.config['training']['cv_folds'],
            shuffle=True,
            random_state=self.config['data']['random_state']
        )
        
        cv_scores = []
        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):
            self.logger.info(f"CV Fold {fold + 1}/{self.config['training']['cv_folds']}")
            
            X_fold_train, X_fold_val = X[train_idx], X[val_idx]
            y_fold_train, y_fold_val = y[train_idx], y[val_idx]
            
            # Train fold model
            fold_ensemble = CyberSecurityEnsemble(ensemble.config)
            fold_ensemble.fit(X_fold_train, y_fold_train)
            
            # Predict and score
            y_pred = fold_ensemble.predict_proba(X_fold_val)
            fold_score = roc_auc_score(y_fold_val, y_pred)
            cv_scores.append(fold_score)
            
            self.logger.info(f"Fold {fold + 1} AUC: {fold_score:.4f}")
        
        return np.array(cv_scores)
    
    def evaluate_model(self, ensemble: CyberSecurityEnsemble,
                      X_test: np.ndarray, y_test: np.ndarray) -> Dict:
        """
        Comprehensive model evaluation
        """
        self.logger.info("Evaluating model on test set...")
        
        # Predictions
        y_pred_proba = ensemble.predict_proba(X_test)
        y_pred = ensemble.predict(X_test, threshold=0.5)
        
        # Metrics
        test_auc = roc_auc_score(y_test, y_pred_proba)
        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
        pr_auc = np.trapz(precision, recall)
        
        # Classification report
        class_report = classification_report(y_test, y_pred, output_dict=True)
        
        # Precision at different recall levels
        precision_at_recalls = {}
        for target_recall in [0.8, 0.9, 0.95]:
            idx = np.argmax(recall >= target_recall)
            if idx > 0:
                precision_at_recalls[f'precision_at_recall_{target_recall}'] = precision[idx]
        
        metrics = {
            'test_auc': test_auc,
            'test_pr_auc': pr_auc,
            'test_precision': class_report['1']['precision'],
            'test_recall': class_report['1']['recall'],
            'test_f1': class_report['1']['f1-score'],
            **precision_at_recalls
        }
        
        # Log metrics to MLflow
        with mlflow.start_run():
            mlflow.log_metrics(metrics)
        
        self.logger.info(f"Test AUC: {test_auc:.4f}")
        self.logger.info(f"Test PR-AUC: {pr_auc:.4f}")
        
        return metrics
    
    def register_model(self, model_name: str = None):
        """
        Register model in MLflow Model Registry
        """
        if model_name is None:
            model_name = self.config['model_registry']['model_name']
        
        try:
            # Get the latest run
            experiment = mlflow.get_experiment_by_name(
                self.config['mlflow']['experiment_name']
            )
            runs = mlflow.search_runs(
                experiment_ids=[experiment.experiment_id],
                order_by=["start_time DESC"],
                max_results=1
            )
            
            if len(runs) > 0:
                run_id = runs.iloc[0]['run_id']
                model_uri = f"runs:/{run_id}/ensemble_models"
                
                # Register model
                mlflow.register_model(
                    model_uri=model_uri,
                    name=model_name
                )
                
                self.logger.info(f"Model registered as {model_name}")
            
        except Exception as e:
            self.logger.error(f"Model registration failed: {e}")
    
    def run_training_pipeline(self, data_path: str):
        """
        Run complete training pipeline
        """
        try:
            # Load and validate data
            df, validation_passed = self.load_and_validate_data(data_path)
            
            if not validation_passed:
                self.logger.warning("Proceeding despite validation issues...")
            
            # Prepare features
            X, y = self.prepare_features(df)
            
            # Split data
            X_train, X_val, X_test, y_train, y_val, y_test = self.split_data(X, y)
            
            # Train model
            ensemble = self.train_model(X_train, y_train, X_val, y_val)
            
            # Evaluate model
            metrics = self.evaluate_model(ensemble, X_test, y_test)
            
            # Register model if performance is good
            if metrics['test_auc'] > 0.85:
                self.register_model()
            else:
                self.logger.warning(f"Model performance too low (AUC: {metrics['test_auc']:.4f})")
            
            self.logger.info("Training pipeline completed successfully!")
            return ensemble, metrics
            
        except Exception as e:
            self.logger.error(f"Training pipeline failed: {e}")
            raise

def main():
    """Main training script"""
    parser = argparse.ArgumentParser(description='Train cybersecurity threat detection model')
    parser.add_argument('--data', required=True, help='Path to training data')
    parser.add_argument('--config', default='configs/model_config.yaml', 
                       help='Path to config file')
    
    args = parser.parse_args()
    
    # Run training pipeline
    pipeline = ModelTrainingPipeline(args.config)
    ensemble, metrics = pipeline.run_training_pipeline(args.data)
    
    print("Training completed!")
    print(f"Final test AUC: {metrics['test_auc']:.4f}")

if __name__ == "__main__":
    main()</code></pre>
                    </div>
                </div>
            </div>
        </section>

        <!-- API Section -->
        <section id="api" class="section-content hidden">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">API & Model Serving</h2>
                <div class="mb-4">
                    <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/f612495f-27ca-4a16-89fe-dd16afa09347.png" alt="API architecture diagram showing FastAPI endpoints, model serving infrastructure, Redis caching, and real-time streaming components with monitoring dashboards" class="w-full rounded-lg shadow-md">
                </div>
                <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                    <pre><code class="language-python"># src/app.py
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
import numpy as np
import pandas as pd
import joblib
import redis
import json
import logging
import time
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import asyncio
import uvicorn
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
import hashlib

from models.ensemble import CyberSecurityEnsemble
from feature_engineering import CyberSecurityFeatureEngineer

# Metrics
PREDICTION_REQUESTS = Counter('prediction_requests_total', 'Total prediction requests', ['model_version'])
PREDICTION_LATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')
ANOMALY_DETECTIONS = Counter('anomaly_detections_total', 'Total anomaly detections', ['severity'])

# Initialize FastAPI app
app = FastAPI(
    title="Cybersecurity Threat Detection API",
    description="Production-ready ML API for detecting cybersecurity threats",
    version="1.0.0"
)

# Security
security = HTTPBearer()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables
model = None
feature_pipeline = None
redis_client = None

# Pydantic models
class NetworkEvent(BaseModel):
    """Input model for network event data"""
    timestamp: Optional[str] = Field(default_factory=lambda: datetime.now().isoformat())
    src_ip: str = Field(..., description="Source IP address")
    dst_ip: str = Field(..., description="Destination IP address")
    src_port: int = Field(..., ge=0, le=65535, description="Source port")
    dst_port: int = Field(..., ge=0, le=65535, description="Destination port")
    protocol: str = Field(..., description="Network protocol (TCP, UDP, etc.)")
    bytes_sent: int = Field(..., ge=0, description="Bytes sent")
    bytes_received: int = Field(..., ge=0, description="Bytes received")
    packets_sent: int = Field(..., ge=0, description="Packets sent")
    packets_received: int = Field(..., ge=0, description="Packets received")
    duration: Optional[float] = Field(default=0, ge=0, description="Session duration in seconds")
    
    @validator('src_ip', 'dst_ip')
    def validate_ip(cls, v):
        import ipaddress
        try:
            ipaddress.ip_address(v)
            return v
        except ValueError:
            raise ValueError(f"Invalid IP address: {v}")

class BatchPredictionRequest(BaseModel):
    """Batch prediction request"""
    events: List[NetworkEvent] = Field(..., min_items=1, max_items=1000)
    return_features: bool = Field(default=False, description="Whether to return engineered features")

class PredictionResponse(BaseModel):
    """Prediction response model"""
    event_id: str
    threat_score: float = Field(..., ge=0, le=1, description="Threat probability score")
    is_suspicious: bool = Field(..., description="Binary threat classification")
    confidence: float = Field(..., ge=0, le=1, description="Model confidence")
    risk_level: str = Field(..., description="Risk level: LOW, MEDIUM, HIGH, CRITICAL")
    contributing_factors: List[str] = Field(default=[], description="Key factors contributing to the score")
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())

class BatchPredictionResponse(BaseModel):
    """Batch prediction response"""
    predictions: List[PredictionResponse]
    processing_time_ms: float
    model_version: str
    total_events: int

class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    model_loaded: bool
    redis_connected: bool
    timestamp: str
    uptime_seconds: float

# Startup event
@app.on_event("startup")
async def startup_event():
    """Initialize models and connections on startup"""
    global model, feature_pipeline, redis_client
    
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    try:
        # Load feature pipeline
        logger.info("Loading feature pipeline...")
        feature_pipeline = joblib.load("models/feature_pipeline.joblib")
        
        # Load model
        logger.info("Loading ensemble model...")
        model = CyberSecurityEnsemble()
        model.load_models("models/ensemble")
        
        # Initialize Redis connection
        logger.info("Connecting to Redis...")
        redis_client = redis.Redis(
            host='localhost', 
            port=6379, 
            db=0, 
            decode_responses=True,
            socket_timeout=5
        )
        redis_client.ping()  # Test connection
        
        logger.info("Startup completed successfully!")
        
    except Exception as e:
        logger.error(f"Startup failed: {e}")
        raise

# Authentication dependency
async def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    """Verify JWT token (implement your auth logic here)"""
    # For demo purposes, accept any token
    # In production, implement proper JWT verification
    if not credentials.token:
        raise HTTPException(status_code=401, detail="Missing authentication token")
    return credentials.token

# Utility functions
def generate_event_id(event: NetworkEvent) -> str:
    """Generate unique event ID"""
    event_string = f"{event.src_ip}:{event.src_port}-{event.dst_ip}:{event.dst_port}-{event.timestamp}"
    return hashlib.md5(event_string.encode()).hexdigest()[:16]

def calculate_risk_level(threat_score: float) -> str:
    """Calculate risk level based on threat score"""
    if threat_score >= 0.9:
        return "CRITICAL"
    elif threat_score >= 0.7:
        return "HIGH"
    elif threat_score >= 0.5:
        return "MEDIUM"
    else:
        return "LOW"

def get_contributing_factors(features: np.ndarray, importance: Dict, top_k: int = 5) -> List[str]:
    """Identify top contributing factors"""
    # This is a simplified version - implement based on your feature importance logic
    factors = [
        "unusual_port_usage",
        "high_bytes_ratio",
        "cross_border_communication",
        "suspicious_timing",
        "anomalous_traffic_pattern"
    ]
    return factors[:top_k]

async def cache_prediction(event_id: str, prediction: Dict, ttl_seconds: int = 3600):
    """Cache prediction in Redis"""
    try:
        if redis_client:
            await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: redis_client.setex(
                    f"prediction:{event_id}", 
                    ttl_seconds, 
                    json.dumps(prediction)
                )
            )
    except Exception as e:
        logging.warning(f"Failed to cache prediction: {e}")

async def get_cached_prediction(event_id: str) -> Optional[Dict]:
    """Get cached prediction from Redis"""
    try:
        if redis_client:
            cached = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: redis_client.get(f"prediction:{event_id}")
            )
            if cached:
                return json.loads(cached)
    except Exception as e:
        logging.warning(f"Failed to get cached prediction: {e}")
    return None

# API Endpoints
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    start_time = getattr(app.state, 'start_time', time.time())
    
    return HealthResponse(
        status="healthy" if model and feature_pipeline else "unhealthy",
        model_loaded=model is not None,
        redis_connected=redis_client is not None and redis_client.ping(),
        timestamp=datetime.now().isoformat(),
        uptime_seconds=time.time() - start_time
    )

@app.post("/predict", response_model=PredictionResponse)
async def predict_single(
    event: NetworkEvent,
    background_tasks: BackgroundTasks,
    token: str = Depends(verify_token)
):
    """Predict threat for a single network event"""
    start_time = time.time()
    
    try:
        # Generate event ID
        event_id = generate_event_id(event)
        
        # Check cache first
        cached_prediction = await get_cached_prediction(event_id)
        if cached_prediction:
            PREDICTION_REQUESTS.labels(model_version="cached").inc()
            return PredictionResponse(**cached_prediction)
        
        # Convert to DataFrame
        event_df = pd.DataFrame([event.dict()])
        
        # Feature engineering
        features = feature_pipeline.transform(event_df)
        
        # Model prediction
        threat_score = float(model.predict_proba(features)[0])
        is_suspicious = threat_score >= 0.5
        
        # Calculate additional metrics
        risk_level = calculate_risk_level(threat_score)
        confidence = min(abs(threat_score - 0.5) * 2, 1.0)  # Distance from decision boundary
        contributing_factors = get_contributing_factors(features, model.get_feature_importance())
        
        # Create response
        prediction = PredictionResponse(
            event_id=event_id,
            threat_score=threat_score,
            is_suspicious=is_suspicious,
            confidence=confidence,
            risk_level=risk_level,
            contributing_factors=contributing_factors
        )
        
        # Cache prediction
        background_tasks.add_task(
            cache_prediction, 
            event_id, 
            prediction.dict()
        )
        
        # Metrics
        PREDICTION_REQUESTS.labels(model_version="v1.0").inc()
        PREDICTION_LATENCY.observe(time.time() - start_time)
        
        if is_suspicious:
            ANOMALY_DETECTIONS.labels(severity=risk_level.lower()).inc()
        
        return prediction
        
    except Exception as e:
        logging.error(f"Prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@app.post("/predict/batch", response_model=BatchPredictionResponse)
async def predict_batch(
    request: BatchPredictionRequest,
    background_tasks: BackgroundTasks,
    token: str = Depends(verify_token)
):
    """Predict threats for multiple network events"""
    start_time = time.time()
    
    try:
        predictions = []
        
        # Convert events to DataFrame
        events_df = pd.DataFrame([event.dict() for event in request.events])
        
        # Feature engineering
        features = feature_pipeline.transform(events_df)
        
        # Batch prediction
        threat_scores = model.predict_proba(features)
        
        # Process each prediction
        for i, (event, threat_score) in enumerate(zip(request.events, threat_scores)):
            event_id = generate_event_id(event)
            threat_score = float(threat_score)
            is_suspicious = threat_score >= 0.5
            
            prediction = PredictionResponse(
                event_id=event_id,
                threat_score=threat_score,
                is_suspicious=is_suspicious,
                confidence=min(abs(threat_score - 0.5) * 2, 1.0),
                risk_level=calculate_risk_level(threat_score),
                contributing_factors=get_contributing_factors(
                    features[i:i+1], 
                    model.get_feature_importance()
                )
            )
            predictions.append(prediction)
            
            # Cache individual predictions
            background_tasks.add_task(
                cache_prediction,
                event_id,
                prediction.dict()
            )
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        # Metrics
        PREDICTION_REQUESTS.labels(model_version="v1.0").inc()
        PREDICTION_LATENCY.observe(time.time() - start_time)
        
        return BatchPredictionResponse(
            predictions=predictions,
            processing_time_ms=processing_time_ms,
            model_version="v1.0",
            total_events=len(request.events)
        )
        
    except Exception as e:
        logging.error(f"Batch prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"Batch prediction failed: {str(e)}")

@app.get("/metrics")
async def get_metrics():
    """Prometheus metrics endpoint"""
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.get("/model/info")
async def get_model_info(token: str = Depends(verify_token)):
    """Get model information"""
    if not model:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    return {
        "model_type": "CyberSecurityEnsemble",
        "version": "1.0.0",
        "features": len(feature_pipeline.named_steps['feature_engineer'].feature_names),
        "models": list(model.models.keys()),
        "last_updated": datetime.now().isoformat()
    }

@app.post("/model/reload")
async def reload_model(token: str = Depends(verify_token)):
    """Reload model from disk"""
    global model, feature_pipeline
    
    try:
        # Reload feature pipeline
        feature_pipeline = joblib.load("models/feature_pipeline.joblib")
        
        # Reload model
        model = CyberSecurityEnsemble()
        model.load_models("models/ensemble")
        
        return {"status": "success", "message": "Model reloaded successfully"}
        
    except Exception as e:
        logging.error(f"Model reload failed: {e}")
        raise HTTPException(status_code=500, detail=f"Model reload failed: {str(e)}")

if __name__ == "__main__":
    # Store start time
    app.state.start_time = time.time()
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8080,
        workers=1,  # Use 1 worker for model consistency
        reload=False,
        access_log=True
    )</code></pre>
                </div>
            </div>
        </section>

        <!-- Agents Section -->
        <section id="agents" class="section-content hidden">
            <div class="bg-white rounded-lg shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold mb-6 text-gray-800">Agentic AI Components</h2>
                
                <!-- Tab Navigation -->
                <div class="flex space-x-4 mb-6 border-b">
                    <button onclick="showTab('agents', 'triage')" class="tab-button px-4 py-2 font-medium text-blue-600 border-b-2 border-blue-600">Triage Agent</button>
                    <button onclick="showTab('agents', 'maintenance')" class="tab-button px-4 py-2 font-medium text-gray-500 hover:text-gray-700">Maintenance Agent</button>
                </div>

                <!-- Triage Agent Tab -->
                <div id="agents-triage" class="tab-content active">
                    <h3 class="text-xl font-semibold mb-4">Real-time Triage Agent</h3>
                    <div class="mb-4">
                        <img src="https://storage.googleapis.com/workspace-0f70711f-8b4e-4d94-86f1-2a93ccde5887/image/79959ebc-988a-424e-b6c0-80c0a720c73d.png" alt="Triage agent workflow diagram showing alert processing, threat enrichment, decision tree, and automated response actions with human escalation paths" class="w-full rounded-lg shadow-md">
                    </div>
                    <div class="code-container bg-gray-900 rounded-lg p-4 mb-4">
                        <pre><code class="language-python"># src/agents/triage_agent.py
import asyncio
import logging
import json
import requests
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import geoip2.database
import whois
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.llms import OpenAI
from langchain.prompts import StringPromptTemplate
from langchain.schema import AgentAction, AgentFinish
import redis
import smtplib
from email.mime.text import MIMEText

class AlertSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class ActionType(Enum):
    BLOCK_IP = "block_ip"
    CREATE_INCIDENT = "create_incident"
    ESCALATE_HUMAN = "escalate_human"
    LOG_SUSPICIOUS = "log_suspicious"
    QUARANTINE = "quarantine"

@dataclass
class ThreatAlert:
    """Threat alert data structure"""
    id: str
    src_ip: str
    dst_ip: str
    threat_score: float
    severity: AlertSeverity
    timestamp: datetime
    features: Dict[str, Any]
    contributing_factors: List[str]
    raw_event: Dict[str, Any]

@dataclass
class EnrichmentData:
    """IP enrichment data"""
    ip: str
    country: Optional[str] = None
    asn: Optional[str] = None
    organization: Optional[str] = None
    is_tor: bool = False
    is_vpn: bool = False
    reputation_score: Optional[float] = None
    previous_incidents: List[Dict] = None

class ThreatTriageAgent:
    """
    Autonomous agent for real-time threat triage and response
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.redis_client = redis.Redis(**config.get('redis', {}))
        self.geoip_reader = None
        self.llm = None
        self.agent_executor = None
        
        # Initialize components
        self._setup_geoip()
        self._setup_llm()
        self._setup_agent()
    
    def _setup_geoip(self):
        """Initialize GeoIP database"""
        try:
            geoip_path = self.config.get('geoip_db_path')
            if geoip_path:
                self.geoip_reader = geoip2.database.Reader(geoip_path)
        except Exception as e:
            self.logger.warning(f"Failed to load GeoIP database: {e}")
    
    def _setup_llm(self):
        """Initialize language model"""
        try:
            openai_api_key = self.config.get('openai_api_key')
            if openai_api_key:
                self.llm = OpenAI(
                    temperature=0.1,
                    openai_api_key=openai_api_key,
                    max_tokens=500
                )
        except Exception as e:
            self.logger.warning(f"Failed to initialize LLM: {e}")
    
    def _setup_agent(self):
        """Setup LangChain agent with tools"""
        tools = [
            Tool(
                name="enrich_ip",
                description="Enrich IP address with geolocation and reputation data",
                func=self.enrich_ip_address
            ),
            Tool(
                name="check_reputation",
                description="Check IP reputation against threat intelligence feeds",
                func=self.check_ip_reputation
            ),
            Tool(
                name="query_incidents",
                description="Query historical incidents for similar patterns",
                func=self.query_similar_incidents
            ),
            Tool(
                name="block_ip",
                description="Block IP address in firewall/WAF",
                func=self.block_ip_address
            ),
            Tool(
                name="create_incident",
                description="Create incident in SIEM/ticketing system",
                func=self.create_security_incident
            ),
            Tool(
                name="notify_soc",
                description="Send notification to Security Operations Center",
                func=self.notify_soc_team
            )
        ]
        
        if self.llm:
            prompt_template = self._create_agent_prompt_template()
            
            class TriageAgentOutputParser:
                def parse(self, llm_output: str):
                    # Simple parsing logic - enhance as needed
                    if "Action:" in llm_output:
                        action = llm_output.split("Action:")[1].split("Action Input:")[0].strip()
                        action_input = llm_output.split("Action Input:")[1].split("Observation:")[0].strip() if "Action Input:" in llm_output else ""
                        return AgentAction(tool=action, tool_input=action_input, log=llm_output)
                    else:
                        return AgentFinish({"output": llm_output}, llm_output)
            
            agent = LLMSingleActionAgent(
                llm_chain=prompt_template | self.llm,
                output_parser=TriageAgentOutputParser(),
                stop=["\nObservation:"],
                allowed_tools=[tool.name for tool in tools]
            )
            
            self.agent_executor = AgentExecutor.from_agent_and_tools(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=5
            )
    
    def _create_agent_prompt_template(self) -> StringPromptTemplate:
        """Create prompt template for the agent"""
        template = """
You are a cybersecurity triage agent. Your job is to analyze threat alerts and take appropriate actions.

Given the following threat alert:
{alert_info}

Available tools:
{tools}

Use the following format:
Thought: Consider what action to take
Action: choose a tool
Action Input: input for the tool
Observation: result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know what to do
Final Answer: summary of actions taken

Begin!
{agent_scratchpad}
"""
        
        class TriagePromptTemplate(StringPromptTemplate):
            template: str = template
            
            def format(self, **kwargs) -> str:
                return self.template.format(**kwargs)
        
        return TriagePromptTemplate(
            input_variables=["alert_info", "tools", "agent_scratchpad"]
        )
    
    async def process_alert(self, alert: ThreatAlert) -> Dict[str, Any]:
        """
        Main entry point for processing threat alerts
        """
        self.logger.info(f"Processing alert {alert.id} with severity {alert.severity.value}")
        
        try:
            # 1. Enrich alert with additional context
            enrichment = await self.enrich_threat_context(alert)
            
            # 2. Determine appropriate response based on severity and context
            response_plan = await self.determine_response_plan(alert, enrichment)
            
            # 3. Execute response actions
            action_results = await self.execute_response_actions(alert, response_plan)
            
            # 4. Log and cache results
            await self.log_triage_decision(alert, enrichment, response_plan, action_results)
            
            return {
                "alert_id": alert.id,
                "status": "processed",
                "enrichment": enrichment,
                "actions_taken": action_results,
                "processing_time": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Failed to process alert {alert.id}: {e}")
            await self.escalate_to_human(alert, f"Processing failed: {e}")
            return {
                "alert_id": alert.id,
                "status": "failed",
                "error": str(e)
            }
    
    async def enrich_threat_context(self, alert: ThreatAlert) -> Dict[str, Any]:
        """
        Enrich alert with additional threat intelligence
        """
        enrichment = {}
        
        # Enrich source IP
        if alert.src_ip:
            src_enrichment = self.enrich_ip_address(alert.src_ip)
            enrichment['src_ip_data'] = src_enrichment
        
        # Enrich destination IP
        if alert.dst_ip:
            dst_enrichment = self.enrich_ip_address(alert.dst_ip)
            enrichment['dst_ip_data'] = dst_enrichment
        
        # Check for similar historical incidents
        similar_incidents = self.query_similar_incidents(alert.features)
        enrichment['similar_incidents'] = similar_incidents
        
        # Calculate risk factors
        risk_factors = self._calculate_risk_factors(alert, enrichment)
        enrichment['risk_factors'] = risk_factors
        
        return enrichment
    
    def enrich_ip_address(self, ip: str) -> EnrichmentData:
        """
        Enrich IP address with geolocation and reputation data
        """
        enrichment = EnrichmentData(ip=ip, previous_incidents=[])
        
        try:
            # GeoIP lookup
            if self.geoip_reader:
                response = self.geoip_reader.city(ip)
                enrichment.country = response.country.iso_code
                if response.traits.autonomous_system_number:
                    enrichment.asn = str(response.traits.autonomous_system_number)
                enrichment.organization = response.traits.autonomous_system_organization
        except Exception as e:
            self.logger.debug(f"GeoIP lookup failed for {ip}: {e}")
        
        # Reputation check
        try:
            enrichment.reputation_score = self.check_ip_reputation(ip)
        except Exception as e:
            self.logger.debug(f"Reputation check failed for {ip}: {e}")
        
        # Check for previous incidents
        try:
            incidents = self._query_previous_incidents(ip)
            enrichment.previous_incidents = incidents
        except Exception as e:
            self.logger.debug(f"Previous incidents query failed for {ip}: {e}")
        
        return enrichment
    
    def check_ip_reputation(self, ip: str) -> float:
        """
        Check IP reputation against threat intelligence feeds
        """
        # Example implementation - integrate with your threat intel sources
        reputation_apis = self.config.get('reputation_apis', [])
        
        total_score = 0
        valid_sources = 0
        
        for api_config in reputation_apis:
            try:
                url = api_config['url'].format(ip=ip)
                headers = api_config.get('headers', {})
                
                response = requests.get(url, headers=headers, timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    score = self._parse_reputation_response(data, api_config['parser'])
                    total_score += score
                    valid_sources += 1
                    
            except Exception as e:
                self.logger.debug(f"Reputation API call failed: {e}")
        
        return total_score / valid_sources if valid_sources > 0 else 0.5
    
    def query_similar_incidents(self, features: Dict[str, Any]) -> List[Dict]:
        """
        Query historical incidents for similar patterns
        """
        try:
            # Use Redis to store and query incident patterns
            # This is a simplified implementation
            
            # Create feature hash for similarity search
            feature_hash = hash(str(sorted(features.items())))
            
            # Query similar patterns
            pattern_key = f"incidents:pattern:{feature_hash}"
            similar = self.redis_client.lrange(pattern_key, 0, 10)
            
            incidents = []
            for incident_json in similar:
                try:
                    incident = json.loads(incident_json)
                    incidents.append(incident)
                except json.JSONDecodeError:
                    continue
            
            return incidents
            
        except Exception as e:
            self.logger.error(f"Failed to query similar incidents: {e}")
            return []
    
    async def determine_response_plan(self, alert: ThreatAlert, enrichment: Dict) -> List[ActionType]:
        """
        Determine appropriate response actions based on alert and enrichment data
        """
        actions = []
        
        # Rule-based decision making
        severity = alert.severity
        threat_score = alert.threat_score
        
        # Get enrichment data
        src_data = enrichment.get('src_ip_data', EnrichmentData(alert.src_ip))
        risk_factors = enrichment.get('risk_factors', {})
        
        # Decision logic
        if severity == AlertSeverity.CRITICAL or threat_score > 0.9:
            actions.extend([
                ActionType.BLOCK_IP,
                ActionType.CREATE_INCIDENT,
                ActionType.ESCALATE_HUMAN
            ])
        elif severity == AlertSeverity.HIGH or threat_score > 0.8:
            # Check additional factors
            if src_data.reputation_score and src_data.reputation_score > 0.7:
                actions.append(ActionType.BLOCK_IP)
            actions.extend([
                ActionType.CREATE_INCIDENT,
                ActionType.ESCALATE_HUMAN
            ])
        elif severity == AlertSeverity.MEDIUM or threat_score > 0.6:
            if len(src_data.previous_incidents) > 2:
                actions.append(ActionType.BLOCK_IP)
            actions.append(ActionType.CREATE_INCIDENT)
        else:
            actions.append(ActionType.LOG_SUSPICIOUS)
        
        # Additional checks
        if risk_factors.get('cross_border') and src_data.country in ['CN', 'RU', 'KP']:
            actions.append(ActionType.BLOCK_IP)
        
        return actions
    
    async def execute_response_actions(self, alert: ThreatAlert, actions: List[ActionType]) -> Dict[str, Any]:
        """
        Execute the determined response actions
        """
        results = {}
        
        for action in actions:
            try:
                if action == ActionType.BLOCK_IP:
                    result = await self.block_ip_address(alert.src_ip)
                elif action == ActionType.CREATE_INCIDENT:
                    result = await self.create_security_incident(alert)
                elif action == ActionType.ESCALATE_HUMAN:
                    result = await self.escalate_to_human(alert, "High severity threat detected")
                elif action == ActionType.LOG_SUSPICIOUS:
                    result = await self.log_suspicious_activity(alert)
                else:
                    result = {"status": "unknown_action"}
                
                results[action.value] = result
                
            except Exception as e:
                self.logger.error(f"Failed to execute action {action.value}: {e}")
                results[action.value] = {"status": "failed", "error": str(e)}
        
        return results
    
    async def block_ip_address(self, ip: str) -> Dict[str, Any]:
        """
        Block IP address in firewall/WAF
        """
        try:
            # Example implementation - integrate with your firewall API
            firewall_api = self.config.get('firewall_api')
            if firewall_api:
                response = requests.post(
                    firewall_api['block_endpoint'],
                    json={"ip": ip, "duration": 3600},  # Block for 1 hour
                    headers=firewall_api.get('headers', {}),
                    timeout=10
                )
                
                if response.status_code == 200:
                    self.logger.info(f"Successfully blocked IP {ip}")
                    return {"status": "success", "ip": ip, "blocked_until": (datetime.now() + timedelta(hours=1)).isoformat()}
                else:
                    return {"status": "failed", "error": f"API returned {response.status_code}"}
            else:
                return {"status": "skipped", "reason": "Firewall API not configured"}
                
        except Exception as e:
            self.logger.error(f"Failed to block IP {ip}: {e}")
            return {"status": "failed", "error": str(e)}
    
    async def create_security_incident(self, alert: ThreatAlert) -> Dict[str, Any]:
        """
        Create incident in SIEM/ticketing system
        """
        try:
            incident_data = {
                "title": f"Cybersecurity Threat Detected - {alert.severity.value.upper()}",
                "description": f"Automated detection of suspicious activity from {alert.src_ip}",
                "severity": alert.severity.value,
                "source_ip": alert.src_ip,
                "destination_ip": alert.dst_ip,
                "threat_score": alert.threat_score,
                "contributing_factors": alert.contributing_factors,
                "timestamp": alert.timestamp.isoformat(),
                "raw_event": alert.raw_event
            }
            
            # Send to SIEM API
            siem_api = self.config.get('siem_api')
            if siem_api:
                response = requests.post(
                    siem_api['incident_endpoint'],
                    json=incident_data,
                    headers=siem_api.get('headers', {}),
                    timeout=10
                )
                
                if response.status_code in [200, 201]:
                    incident_id = response.json().get('incident_id', 'unknown')
                    self.logger.info(f"Created incident {incident_id} for alert {alert.id}")
                    return {"status": "success", "incident_id": incident_id}
                else:
                    return {"status": "failed", "error": f"SIEM API returned {response.status_code}"}
            
            # Fallback: store in Redis
            incident_key = f"incident:{alert.id}:{datetime.now().strftime('%Y%m%d%H%M%S')}"
            self.redis_client.setex(incident_key, 86400 * 7, json.dumps(incident_data))  # Store for 7 days
            
            return {"status": "success", "stored_in": "redis", "key": incident_key}
            
        except Exception as e:
            self.logger.error(f"Failed to create incident for alert {alert.id}: {e}")
            return {"status": "failed", "error": str(e)}
    
    async def escalate_to_human(self, alert: ThreatAlert, reason: str) -> Dict[str, Any]:
        """
        Escalate alert to human analysts
        """
        try:
            escalation_data = {
                "alert_id": alert.id,
                "severity": alert.severity.value,
                "reason": reason,
                "src_ip": alert.src_ip,
                "threat_score": alert.threat_score,
                "timestamp": alert.timestamp.isoformat(),
                "requires_immediate_attention": alert.severity in [AlertSeverity.HIGH, AlertSeverity.CRITICAL]
            }
            
            # Send to SOC team
            await self.notify_soc_team(escalation_data)
            
            # Create high-priority ticket
            if alert.severity == AlertSeverity.CRITICAL:
                await self._send_urgent_notification(escalation_data)
            
            return {"status": "success", "escalated_at": datetime.now().isoformat()}
            
        except Exception as e:
            self.logger.error(f"Failed to escalate alert {alert.id}: {e}")
            return {"status": "failed", "error": str(e)}
    
    async def notify_soc_team(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Send notification to Security Operations Center
        """
        try:
            # Send to Slack/Teams
            webhook_url = self.config.get('soc_webhook_url')
            if webhook_url:
                message = {
                    "text": f"🚨 Security Alert: {data.get('severity', 'Unknown').upper()}",
                    "attachments": [
                        {
                            "color": "danger" if data.get('severity') in ['high', 'critical'] else "warning",
                            "fields": [
                                {"title": "Alert ID", "value": data.get('alert_id', 'N/A'), "short": True},
                                {"title": "Source IP", "value": data.get('src_ip', 'N/A'), "short": True},
                                {"title": "Threat Score", "value": str(data.get('threat_score', 'N/A')), "short": True},
                                {"title": "Timestamp", "value": data.get('timestamp', 'N/A'), "short": True}
                            ]
                        }
                    ]
                }
                
                response = requests.post(webhook_url, json=message, timeout=10)
                
                if response.status_code == 200:
                    return {"status": "success", "channel": "slack"}
                else:
                    return {"status": "failed", "error": f"Webhook returned {response.status_code}"}
            
            return {"status": "skipped", "reason": "No webhook configured"}
            
        except Exception as e:
            self.logger.error(f"Failed to notify SOC team: {e}")
            return {"status": "failed", "error": str(e)}
    
    def _calculate_risk_factors(self, alert: ThreatAlert, enrichment: Dict) -> Dict[str, Any]:
        """
        Calculate additional risk factors
        """
        risk_factors = {}
        
        src_data = enrichment.get('src_ip_data', EnrichmentData(alert.src_ip))
        
        # Geographic risk
        high_risk_countries = ['CN', 'RU', 'KP', 'IR']
        risk_factors['high_risk_country'] = src_data.country in high_risk_countries
        
        # Cross-border communication
        dst_data = enrichment.get('dst_ip_data', EnrichmentData(alert.dst_ip))
        risk_factors['cross_border'] = src_data.country != dst_data.country
        
        # Repeat offender
        risk_factors['repeat_offender'] = len(src_data.previous_incidents) > 0
        
        # Time-based risk (attacks often happen outside business hours)
        if isinstance(alert.timestamp, datetime):
            hour = alert.timestamp.hour
            risk_factors['outside_business_hours'] = hour < 8 or hour > 18
        
        # Feature-based risk factors
        features = alert.features
        risk_factors['high_byte_ratio'] = features.get('bytes_ratio', 0) > 0.9
        risk_factors['unusual_port'] = features.get('dst_port', 80) > 1024
        
        return risk_factors
    
    async def log_triage_decision(self, alert: ThreatAlert, enrichment: Dict, 
                                 actions: List[ActionType], results: Dict) -> None:
        """
        Log triage decision for audit and learning
        """
        try:
            log_entry = {
                "alert_id": alert.id,
                "timestamp": datetime.now().isoformat(),
                "original_alert": {
                    "severity": alert.severity.value,
                    "threat_score": alert.threat_score,
                    "src_ip": alert.src_ip,
                    "dst_ip": alert.dst_ip
                },
                "enrichment_summary": {
                    "src_country": enrichment.get('src_ip_data', {}).get('country'),
                    "reputation_score": enrichment.get('src_ip_data', {}).get('reputation_score'),
                    "similar_incidents_count": len(enrichment.get('similar_incidents', []))
                },
                "actions_planned": [action.value for action in actions],
                "action_results": results,
                "processing_duration_ms": (datetime.now() - alert.timestamp).total_seconds() * 1000
            }
            
            # Store in Redis for analysis
            log_key = f"triage_log:{alert.id}"
            self.redis_client.setex(log_key, 86400 * 30, json.dumps(log_entry))  # Keep for 30 days
            
        except Exception as e:
            self.logger.error(f"Failed to log triage decision: {e}")

# Usage example
async def main():
    """Example usage of the triage agent"""
    config = {
        '
